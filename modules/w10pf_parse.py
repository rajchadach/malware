########################
# Windows 10 Prefetch Parser
# Created by 505Forensics (http://www.505forensics.com)
#
# Usage: Utilize this script to parse either a single or set of Windows 10 prefetch files
#
# Dependencies: This script requires the installation of libscca (https://github.com/libyal/libscca), and was only tested in a Linux environment
#
# Output: Script will output in CSV to stdout by default.
# Reference: https://github.com/bromiley/tools/blob/master/win10_prefetch/w10pf_parse.py
#######################
import argparse
import csv
import sys
import os, struct
import json
import re
import pathlib
# Try importing pyscca; fail if it doesn't import

try:
    import pyscca #Import pyscca, necessary from libscca
except ImportError:
    print("Please install libscca with Python bindings")

output = {}
malF = ""
# Parse individual file. Output is placed in 'output' dictionary
class Prefetch:

    def __init__(self, malF):
        self.malF = malF
        self.roam_file = []

    def parse_file(self, pf_file):
        try:
            scca = pyscca.open(pf_file)
            #if str(scca.get_executable_filename()).lower() == "test.exe":
            last_run_times = []
            for x in range(8): #8
                if scca.get_last_run_time_as_integer(x) > 0:
                    last_run_times.append(scca.get_last_run_time(x).strftime("%Y-%m-%d %H:%M:%S")) #str conversion utilized to change from datetime into human-readable
                else:
                    last_run_times.append('N/A')
            output[str(scca.executable_filename)] = [str(scca.run_count), last_run_times]
            output[str(scca.executable_filename)].append(scca.number_of_filenames)
            user_volumes = []
            window_volumes = []
            prog_files = []
            all_volumes = []
            temp_location = ""
            for volume_information in scca.filenames:
                all_volumes.append(volume_information)
                if "temp" in volume_information.lower():
                    #volume = [str(volume_information.device_path), volume_information.creation_time.strftime("%Y-%m-%d %H:%M:%S"), format(volume_information.serial_number,'x').upper()]
                    user_volumes.append(volume_information)
                if "powershell.exe" in volume_information.lower() or re.findall(r"(?:windows\\\w+\\\w+.exe)", volume_information.lower()):
                    window_volumes.append(volume_information)
                if re.findall(r"(?:PROGRAM FILES|PROGRAM FILES (X86)\\)", volume_information.lower()):
                    temp_location = "Program Folder"
                    prog_files.append(volume_information)
                if re.findall(r"(?:temp|appdata)", volume_information.lower()):
                    temp_location = "User Folder"
                if "windows\\temp" in volume_information.lower():
                    temp_location = "Windows System Folder"
            output[str(scca.executable_filename)].append(all_volumes)
            output[str(scca.executable_filename)].append(temp_location)
            output[str(scca.executable_filename)].append(user_volumes)
            output[str(scca.executable_filename)].append(window_volumes)
            output[str(scca.executable_filename)].append(prog_files)
            for vol in all_volumes:
                if "\\APPDATA\\ROAMING\\" in vol:
                    self.roam_file.append(str(vol).split("\\")[-1])
            return output, self.roam_file
            #print(scca_file.number_of_filenames)
            """ 
            mapped_files = []
            for entry_index, file_metrics in enumerate(scca.file_metrics_entries):
                mapped_file_string = file_metrics.filename
                file_reference = file_metrics.file_reference
                if file_reference:
                    # mapped_file_string = (u'{0:s} [MFT entry: {1:d}, sequence: {2:d}]').format(mapped_file_string, file_reference & 0xffffffffffff, file_reference >> 48)
                    mapped_file_string = u'{0:s}'.format(mapped_file_string)
                    mapped_files.append(mapped_file_string)
            output[str(scca.executable_filename)].append(mapped_files)
            """
        except:
            return None

    # Parse an entire directory of Prefetch files. Note that it searches based on .pf extension
    def parse_dir(self, dir):
        if self.malF.endswith("."):
            self.malF = self.malF.split(".")[0].lower()
        else:
            self.malF = self.malF.lower()
        for file in os.scandir(dir):
            if re.findall(r"(^test.exe|^winword.exe|^jetservice.exe)", str(file.name.lower())):
                return self.parse_file(os.path.join(dir, file))
            else:
                count = 0
                proc_n = str(file.name.lower())
                for i in range(0, 6):
                    if self.malF[i:i + 3] == proc_n[i:i + 3]:
                        count += 1
                if count >= 3:
                    return self.parse_file(os.path.join(dir, file))

    def outputResults(self, output):
        # write json file
        """
        json_output = {}
        for k, v in output.items():
            json_output = {
                    'Executable Name': k,
                    'Run Count': v[0],
                    'Hash of File\'s path':  v[1]
            }
            #Let the script iterate through run times for us, instead of just dumping a list
            run_list = {}
            for i in range(8):
                run_list['Run Time {}'.format(i)] = v[2][i]

            json_output.update({'Run Times': run_list, 'Number of resources': v[3]})

            # Logic to include volume information if its requested by the analyst
            if volume_information:
                volume_list = {}
                for i in range(v[3]):
                    volume_info = {
                            'Volume Name' : v[4][i][0],
                            'Creation Time': v[4][i][1],
                            'Serial Number': v[4][i][2]
                    }
                    volume_list['Volume {}'.format(i)] = volume_info

                volumes = {
                        'Number of Volumes': v[3],
                        'Volume Information': volume_list
                }
                json_output['Volumes'] = volumes
            json_output.update({'Temporary File Location': v[4], 'Loaded resources': v[5]})
            with open("prefetch.json",'w') as file:
                json.dump(json_output,file)

            #print(json.dumps(json_output,indent=6))
        """
        # Write csv file
        headers = ['Executable Name', 'Run Count']
        for i in range(8): # Loop through numbers to create headers
            headers.append('Last Run Time {}'.format(i))
        headers.append('Number of resources')
        headers.append('All loaded resources')
        headers.append('Temporary File Location')
        headers.append('User Loaded resources')
        headers.append('Windows Loaded resources')
        headers.append('Program Files Loaded resources')
        headers.append('Real Filename')
        """
        if volume_information:
            # Add in number of volumes header
            headers.append('Number of Volumes')
            # Need to get the max value of the number of volumes, and create our headers accordingly. Note that some files will have less volumes than others, and will have blank cells where appropriate
            volume_count = []
            for k, v in output.items():
                volume_count.append(v[3])
            for i in range(max(volume_count)):
                # Adding in volume-specific headers one-by-one, simply to avoid list formatting in the CSV output
                headers.append(str('Volume {} Name').format(i))
                headers.append(str('Volume {} Creation Time').format(i))
                headers.append(str('Volume {} Serial Number').format(i))
        """
        with open("/Users/koyko/Documents/prefetch.csv", 'a') as file:
            csv_out = csv.writer(file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
            csv.field_size_limit(50000)
            for k, v in output.items():
                row = [k, v[0]]
                for i in range(8): #8
                    row.append(v[1][i])
                """
                if volume_information:
                    row.append(v[3])
                    for i in range(v[3]):
                        #Iterate through each volume information list to include values
                        for j in range(3):
                            row.append(v[4][i][j])
                """
                row.append(v[2])
                row.append(v[3])
                row.append(v[4])
                row.append(v[5])
                row.append(v[6])
                row.append(v[7])
                row.append(self.malF)
                """ 
                for i in range(len(v[6])):
                    headers.append('Loaded resources {}'.format(i + 1))
                    # Iterate through each volume information list to include values
                    row.append(v[6][i])
                """
            csv_out.writerow(headers)
            csv_out.writerow(row)